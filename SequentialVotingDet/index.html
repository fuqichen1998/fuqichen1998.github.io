<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
	<title>Sequential Voting with Relational Box Fields for Active Object Detection</title>
	<meta property="og:image" content="resources/teaser.pdf"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="Sequential Voting with Relational Box Fields for Active Object Detection" />
	<meta property="og:description" content="Sequential Voting with Relational Box Fields for Active Object Detection" />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:34px">Sequential Voting with Relational Box Fields for Active Object Detection</span>
		<br><br>
		<table align=center width=600px>
			<table align=center width=600px>
				<tr>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://fuqichen1998.github.io/">Qichen Fu</a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://xingyul.github.io/">Xingyu Liu</a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="http://www.cs.cmu.edu/~kkitani/">Kris M. Kitani</a></span>
						</center>
					</td>
				</tr>
			</table>
			<br>
			<table>
				<tr>
					<td align=center>
						<center>
							<span style="font-size:18px">Carnegie Mellon University</span>
						</center>
					</td>
				</tr>
			</table>
			<br>
			<center>
				<span style="font-size:24px">CVPR 2022</span>
			</center>
			<br>

			<table align=center width=400px>
				<tr>
					<td align=center width=200px>
						<center>
							<span style="font-size:18px"><a href='https://arxiv.org/abs/2110.11524'>[Paper]</a></span>
						</center>
					</td>
					<td align=center width=200px>
						<center>
							<span style="font-size:18px"><a href='https://github.com/fuqichen1998/SequentialVotingDet'>[GitHub]</a></span><br>
						</center>
					</td>
				</tr>
			</table>
		</table>
	</center>

	<center>
		<table align=center width=850px>
			<tr>
				<td width=260px>
					<center>
						<img class="round" style="width:500px" src="./resources/teaser.png" />
					</center>
				</td>
			</tr>
		</table>
	</center>

	<hr>

	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				A key component of understanding hand-object interactions is the ability to identify the active object -- the object
				that is being manipulated by the human hand.
				In order to accurately localize the active object, any method must reason using information encoded by each image pixel,
				such as whether it belongs to the hand, the object, or the background.
				To leverage each pixel as evidence to determine the bounding box of the active object, we propose a pixel-wise voting
				function.
				Our pixel-wise voting function takes an initial bounding box as input and produces an improved bounding box of the
				active object as output.
				The voting function is designed so that each pixel inside of the input bounding box votes for an improved bounding box,
				and the box with the majority vote is selected as the output.
				We call the collection of bounding boxes generated inside of the voting function, the Relational Box Field, as it
				characterizes a field of bounding boxes defined in relationship to the current bounding box.
				While our voting function is able to improve the bounding box of the active object, one round of voting is typically not
				enough to accurately localize the active object.
				Therefore, we repeatedly apply the voting function to sequentially improve the location of the bounding box. However,
				since it is known that repeatedly applying a one-step predictor (i.e., auto-regressive processing with our voting
				function) can cause a data distribution shift, we mitigate this issue using reinforcement learning (RL).
				We adopt standard RL to learn the voting function parameters and show that it provides a meaningful improvement over a
				standard supervised learning approach.
				We perform experiments on two large-scale datasets: 100DOH and MECCANO, improving AP50 performance by 8% and 30%,
				respectively, over the state of the art.
			</td>
		</tr>
	</table>

	<br>
	<hr>
	
	<table align=center width=800px>
		<center>
			<h1>Talk</h1>
		</center>
		<p align="center">
			<iframe width="672" height="378" src="https://www.youtube.com/embed/uwyJHGtV-FA" frameborder="0"
				allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
				allowfullscreen></iframe>
		</p>
		<tr>
			<td><span style="font-size:14pt">
					<center>
						<a href='./resources/slides.pdf'>[Slides]</a>
					</center>
			</td>
		</tr>
	</table>
	
	<br>
	<hr>

	<table align=center width=850px>
		<center>
			<h1>Method</h1>
		</center>
		<tr>
			<td>
				To achieve robust object localization, especially under occlusion, we propose a voting function with the Relational Box Field 
				that allows each pixel in the image to vote for a bounding box of the active object. Then we progressively refine it towards a more accurate
				active object bounding box in a sequential decision-making process modeled by a Markov decision process (MDP).
			</td>
		</tr>
		<tr>
			<td style="padding:5px">
				<center>
					<img class="round" style="width:850px" src="./resources/method_diagram.png" />
				</center>
			</td>
		</tr>
	</table>

	<br>
	<hr>
	
	<table align=center width=850px>
		<center>
			<h1>Results</h1>
		</center>
		<tr>
			<td>
				We present the qualitative results of our method below. In the figures, each green arrow points from a hand bounding box (blue) to 
				the corresponding active object bounding box (red). The visualization shows that our method is able to robustly detect the active 
				object under scenes with overlapping objects and severe occlusions. Most failure cases are due to wrong hand detection, motion blur, 
				and insufficient feature from tiny hands and objects. Please check our paper for further results and comparisons.
			</td>
		</tr>
		<tr>
			<td style="padding:5px">
				<center>
					<img class="round" style="width:850px" src="./resources/qualitative_100doh.png" />
					<figcaption>Qualitative Results on 100DOH Dataset</figcaption>
				</center>
			</td>
		</tr>
		<tr>
			<td style="padding:5px">
				<center>
					<img class="round" style="width:850px" src="./resources/qualitative_meccano.png" />
					<figcaption>Qualitative Results on MECCANO Dataset</figcaption>
				</center>
			</td>
		</tr>
	</table>

	<br>
	<hr>

	<table align=center width=850px>
		<center>
			<h1>Analysis</h1>
		</center>
		<tr>
			<td>
				We visualize the IoU (red indicates higher IoU) between the final active object box estimation (red) and the pixel-wise
				predictions inside the hand bounding box (blue). The visualizations show our voting function is able to adapt
				predictions from informative hand parts like fingers as opposed to irrelevant parts like wrist and background. Every visualization
				sample below only shows one pair of hands and objects for better visibility.
			</td>
		</tr>
		<tr>
			<td style="padding:5px">
				<center>
					<img class="round" style="width:850px" src="./resources/voting_IoU_1.png" />
				</center>
			</td>
		</tr>
		<tr>
			<td style="padding:5px">
				<center>
					<img class="round" style="width:850px" src="./resources/voting_IoU_2.png" />
				</center>
			</td>
		</tr>
		<tr>
			<td style="padding:5px">
				<center>
					<img class="round" style="width:850px" src="./resources/voting_IoU_3.png" />
				</center>
			</td>
		</tr>
		<tr>
			<td style="padding:5px">
				<center>
					<img class="round" style="width:850px" src="./resources/voting_IoU_4.png" />
				</center>
			</td>
		</tr>
	</table>
	
	<br>
	<hr>

	<table align=center width=450px>
		<center><h1>Paper and Supplementary Material</h1></center>
		<tr>
			<td><a href="https://arxiv.org/abs/2110.11524"><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
			<td><span style="font-size:14pt">Qichen Fu, Xingyu Liu, Kris M. Kitani<br>
				<b>Sequential Voting with Relational Box Fields for Active Object Detection</b><br>
				CVPR, 2022.<br>
				(hosted on <a href="https://arxiv.org/abs/2110.11524">ArXiv</a>)<br>
			</td>
		</tr>
	</table>
	<br>
	<table align=center width=600px>
		<tr>
			<td><span style="font-size:14pt"><center>
				<a href="./resources/bibtex.txt">[Bibtex]</a>
			</center></td>
		</tr>
	</table>

	<hr>
	<br>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					This work is funded in part by JST AIP Acceleration, Grant Number JPMJCR20U1, Japan. This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project; the code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.
				</left>
			</td>
		</tr>
	</table>
	
	<br>
	<br>
	<br>
	<br>
	<table align=center width=100px>
		<tr>
			<td width=100px>
				<script type="text/javascript" id="clstr_globe"
					src="//clustrmaps.com/globe.js?d=s7ravWHvQvcLzOEwsCdMEMJthzKsGYByqnmhnUpkA2w"></script>
			</td>
		</tr>
	</table>
<br>
</body>
</html>

